{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the Required Packages and Libraies are installed.\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc\n",
    "import os, glob, pickle\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import noisereduce as nr\n",
    "import soundfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the required RAVDESS DataSet with length of 1439 Audio Files \n",
    "os.listdir(path='/Users/satyamshandilya/ML Project/speech-emotion-recognition-ravdess-data')\n",
    "def getListOfFiles(dirName):\n",
    "    listOfFile=os.listdir(dirName)\n",
    "    allFiles=list()\n",
    "    for entry in listOfFile:\n",
    "        fullPath=os.path.join(dirName, entry)\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles=allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "    return allFiles\n",
    "\n",
    "dirName = './speech-emotion-recognition-ravdess-data'\n",
    "listOfFiles = getListOfFiles(dirName)\n",
    "len(listOfFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Cleaning Step is Performed where:\n",
    "#DOWN SAMPLING OF AUDIO FILES IS DONE  AND PUT MASK OVER IT AND DIRECT INTO CLEAN FOLDER\n",
    "#MASK IS TO REMOVE UNNECESSARY EMPTY VOIVES AROUND THE MAIN AUDIO VOICE \n",
    "def envelope(y , rate, threshold):\n",
    "    mask=[]\n",
    "    y=pd.Series(y).apply(np.abs)\n",
    "    y_mean = y.rolling(window=int(rate/10) ,  min_periods=1 , center = True).mean()\n",
    "    for mean in y_mean:\n",
    "        if mean>threshold:\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1439/1439 [00:37<00:00, 38.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob,pickle\n",
    "for file in tqdm(glob.glob('/Users/satyamshandilya/ML Project/speech-emotion-recognition-ravdess-data//**//*.wav')):\n",
    "    file_name = os.path.basename(file)\n",
    "    signal , rate = librosa.load(file, sr=16000)\n",
    "    mask = envelope(signal,rate, 0.0005)\n",
    "    wavfile.write(filename= '/Users/satyamshandilya/ML Project/clean_speech//'+str(file_name), rate=rate,data=signal[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction of Audio Files Function \n",
    "#Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotions in the RAVDESS dataset to be classified Audio Files based on . \n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "#These are the emotions User wants to observe more :\n",
    "observed_emotions=['calm', 'happy', 'angry', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and extract features for each sound file\n",
    "from glob import glob\n",
    "import os\n",
    "import glob\n",
    "def load_data(test_size=0.33):\n",
    "    x,y=[],[]\n",
    "    answer = 0\n",
    "    for file in glob.glob('/Users/satyamshandilya/ML Project/clean_speech//*.wav'):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            answer += 1\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append([emotion,file_name])\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 180) (192, 180) (576, 2) (192, 2)\n",
      "(576,) (192,)\n",
      "03-01-03-02-02-01-16.wav\n",
      "03-01-03-01-02-01-17.wav\n",
      "03-01-03-01-02-02-05.wav\n",
      "03-01-02-01-01-01-21.wav\n",
      "03-01-05-02-01-01-21.wav\n",
      "03-01-02-01-02-02-01.wav\n",
      "03-01-07-01-02-01-17.wav\n",
      "03-01-03-02-02-02-04.wav\n",
      "03-01-03-02-02-01-14.wav\n",
      "03-01-07-01-01-02-17.wav\n",
      "03-01-07-02-02-01-12.wav\n",
      "03-01-05-01-02-02-07.wav\n",
      "03-01-07-02-01-02-09.wav\n",
      "03-01-02-02-01-02-01.wav\n",
      "03-01-05-02-01-02-06.wav\n",
      "03-01-02-02-01-02-19.wav\n",
      "03-01-05-01-02-01-17.wav\n",
      "03-01-03-01-02-02-13.wav\n",
      "03-01-05-01-01-02-14.wav\n",
      "03-01-05-02-01-01-14.wav\n",
      "03-01-03-01-02-02-21.wav\n",
      "03-01-05-02-02-01-23.wav\n",
      "03-01-05-02-02-02-13.wav\n",
      "03-01-07-02-01-01-21.wav\n",
      "03-01-03-01-02-02-23.wav\n",
      "03-01-05-02-02-01-24.wav\n",
      "03-01-05-02-02-02-12.wav\n",
      "03-01-03-01-02-01-13.wav\n",
      "03-01-07-02-01-02-24.wav\n",
      "03-01-02-02-01-02-23.wav\n",
      "03-01-03-01-02-01-09.wav\n",
      "03-01-03-01-02-02-14.wav\n",
      "03-01-05-01-01-01-10.wav\n",
      "03-01-03-02-01-01-02.wav\n",
      "03-01-03-01-01-01-15.wav\n",
      "03-01-02-02-02-01-02.wav\n",
      "03-01-03-02-02-01-05.wav\n",
      "03-01-07-01-02-01-11.wav\n",
      "03-01-02-02-02-01-12.wav\n",
      "03-01-05-01-01-02-23.wav\n",
      "03-01-07-01-01-01-24.wav\n",
      "03-01-02-02-01-01-16.wav\n",
      "03-01-05-02-02-02-04.wav\n",
      "03-01-07-02-02-02-15.wav\n",
      "03-01-07-01-02-02-20.wav\n",
      "03-01-07-02-02-01-11.wav\n",
      "03-01-07-01-01-02-02.wav\n",
      "03-01-05-02-02-01-03.wav\n",
      "03-01-05-01-02-01-04.wav\n",
      "03-01-05-02-01-01-01.wav\n",
      "03-01-02-02-01-02-11.wav\n",
      "03-01-05-02-01-02-08.wav\n",
      "03-01-07-02-01-02-10.wav\n",
      "03-01-05-01-02-01-11.wav\n",
      "03-01-05-01-02-01-20.wav\n",
      "03-01-03-02-02-02-09.wav\n",
      "03-01-02-02-02-02-10.wav\n",
      "03-01-05-01-02-01-01.wav\n",
      "03-01-03-02-01-01-01.wav\n",
      "03-01-02-01-02-01-13.wav\n",
      "03-01-02-02-01-01-17.wav\n",
      "03-01-05-02-02-02-17.wav\n",
      "03-01-07-02-01-01-05.wav\n",
      "03-01-03-01-02-01-22.wav\n",
      "03-01-05-01-02-01-12.wav\n",
      "03-01-02-01-02-02-06.wav\n",
      "03-01-02-01-02-01-06.wav\n",
      "03-01-03-02-01-01-05.wav\n",
      "03-01-03-02-02-01-15.wav\n",
      "03-01-03-01-02-01-08.wav\n",
      "03-01-02-02-01-01-08.wav\n",
      "03-01-03-01-01-02-11.wav\n",
      "03-01-05-01-01-01-08.wav\n",
      "03-01-03-01-02-02-08.wav\n",
      "03-01-02-02-02-01-03.wav\n",
      "03-01-03-02-02-02-05.wav\n",
      "03-01-03-01-01-01-08.wav\n",
      "03-01-05-01-01-01-05.wav\n",
      "03-01-07-01-02-02-13.wav\n",
      "03-01-02-01-01-01-05.wav\n",
      "03-01-02-02-02-02-02.wav\n",
      "03-01-02-01-02-02-23.wav\n",
      "03-01-05-02-01-02-17.wav\n",
      "03-01-07-01-01-02-14.wav\n",
      "03-01-05-01-01-01-07.wav\n",
      "03-01-03-01-01-02-04.wav\n",
      "03-01-07-01-02-02-18.wav\n",
      "03-01-05-02-02-01-10.wav\n",
      "03-01-07-01-01-01-22.wav\n",
      "03-01-05-02-01-02-01.wav\n",
      "03-01-07-01-02-01-09.wav\n",
      "03-01-05-01-02-02-20.wav\n",
      "03-01-02-01-01-02-14.wav\n",
      "03-01-07-02-02-02-23.wav\n",
      "03-01-05-01-01-01-20.wav\n",
      "03-01-07-01-01-01-12.wav\n",
      "03-01-05-01-01-02-04.wav\n",
      "03-01-02-02-02-01-16.wav\n",
      "03-01-07-02-02-01-18.wav\n",
      "03-01-02-02-02-02-16.wav\n",
      "03-01-02-02-02-01-10.wav\n",
      "03-01-02-02-01-01-22.wav\n",
      "03-01-07-01-01-01-17.wav\n",
      "03-01-03-02-02-01-13.wav\n",
      "03-01-02-01-02-01-17.wav\n",
      "03-01-03-01-02-02-02.wav\n",
      "03-01-02-02-01-01-04.wav\n",
      "03-01-03-01-01-02-06.wav\n",
      "03-01-03-01-01-02-16.wav\n",
      "03-01-02-02-01-01-05.wav\n",
      "03-01-07-02-02-02-06.wav\n",
      "03-01-07-02-02-01-24.wav\n",
      "03-01-05-01-01-02-16.wav\n",
      "03-01-03-02-02-02-02.wav\n",
      "03-01-07-01-02-01-13.wav\n",
      "03-01-07-02-02-01-05.wav\n",
      "03-01-03-02-02-02-15.wav\n",
      "03-01-02-02-01-01-11.wav\n",
      "03-01-03-02-01-02-18.wav\n",
      "03-01-03-02-01-01-07.wav\n",
      "03-01-05-01-01-02-02.wav\n",
      "03-01-05-01-01-02-01.wav\n",
      "03-01-03-02-01-02-24.wav\n",
      "03-01-05-01-02-01-15.wav\n",
      "03-01-03-01-01-02-05.wav\n",
      "03-01-05-02-01-01-10.wav\n",
      "03-01-05-01-02-02-15.wav\n",
      "03-01-03-02-02-02-12.wav\n",
      "03-01-03-02-01-02-04.wav\n",
      "03-01-02-02-01-02-16.wav\n",
      "03-01-03-01-02-01-24.wav\n",
      "03-01-07-01-02-02-11.wav\n",
      "03-01-03-02-02-01-03.wav\n",
      "03-01-05-01-01-01-15.wav\n",
      "03-01-02-02-02-02-03.wav\n",
      "03-01-02-02-01-01-18.wav\n",
      "03-01-03-02-01-02-13.wav\n",
      "03-01-05-02-01-01-02.wav\n",
      "03-01-05-02-02-01-06.wav\n",
      "03-01-03-01-02-01-07.wav\n",
      "03-01-02-02-02-02-07.wav\n",
      "03-01-02-02-02-01-04.wav\n",
      "03-01-07-02-01-01-11.wav\n",
      "03-01-03-02-01-02-09.wav\n",
      "03-01-07-02-02-02-07.wav\n",
      "03-01-03-01-02-01-11.wav\n",
      "03-01-03-01-02-01-19.wav\n",
      "03-01-05-02-02-02-09.wav\n",
      "03-01-05-01-02-01-08.wav\n",
      "03-01-02-02-02-01-07.wav\n",
      "03-01-07-01-01-01-23.wav\n",
      "03-01-02-02-02-02-23.wav\n",
      "03-01-03-01-01-02-19.wav\n",
      "03-01-05-02-01-01-17.wav\n",
      "03-01-02-01-02-02-03.wav\n",
      "03-01-02-02-01-02-02.wav\n",
      "03-01-05-02-02-02-22.wav\n",
      "03-01-07-02-02-02-19.wav\n",
      "03-01-07-01-01-02-06.wav\n",
      "03-01-07-01-02-02-07.wav\n",
      "03-01-02-01-02-01-04.wav\n",
      "03-01-07-02-01-01-20.wav\n",
      "03-01-03-01-01-01-05.wav\n",
      "03-01-02-02-01-01-06.wav\n",
      "03-01-02-01-02-01-12.wav\n",
      "03-01-03-01-01-01-17.wav\n",
      "03-01-07-02-01-02-12.wav\n",
      "03-01-03-02-01-01-10.wav\n",
      "03-01-03-02-02-01-11.wav\n",
      "03-01-03-02-02-01-23.wav\n",
      "03-01-07-01-02-02-21.wav\n",
      "03-01-05-01-01-02-20.wav\n",
      "03-01-03-02-01-02-14.wav\n",
      "03-01-02-01-02-02-16.wav\n",
      "03-01-07-01-02-01-20.wav\n",
      "03-01-03-01-01-02-14.wav\n",
      "03-01-05-01-01-02-19.wav\n",
      "03-01-03-01-01-02-24.wav\n",
      "03-01-05-01-02-02-24.wav\n",
      "03-01-05-02-01-02-11.wav\n",
      "03-01-05-02-01-02-02.wav\n",
      "03-01-02-02-02-02-18.wav\n",
      "03-01-02-02-02-02-14.wav\n",
      "03-01-03-02-02-01-04.wav\n",
      "03-01-05-02-02-02-23.wav\n",
      "03-01-07-02-01-02-21.wav\n",
      "03-01-03-02-01-02-17.wav\n",
      "03-01-02-02-02-01-05.wav\n",
      "03-01-07-01-01-02-20.wav\n",
      "03-01-03-01-01-01-13.wav\n",
      "03-01-07-01-02-01-02.wav\n",
      "03-01-03-01-01-02-17.wav\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset\n",
    "import librosa\n",
    "import numpy as np\n",
    "# x_train,x_test,y_trai,y_tes=load_data(test_size=0.25)\n",
    "print(np.shape(x_train),np.shape(x_test), np.shape(y_trai),np.shape(y_tes))\n",
    "y_test_map = np.array(y_tes).T\n",
    "y_test = y_test_map[0]\n",
    "test_filename = y_test_map[1]\n",
    "y_train_map = np.array(y_trai).T\n",
    "y_train = y_train_map[0]\n",
    "train_filename = y_train_map[1]\n",
    "print(np.shape(y_train),np.shape(y_test))\n",
    "print(*test_filename,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.90711548e+02  4.63122864e+01 -2.51764641e+01 -3.83111382e+00\n",
      " -1.75483227e+01 -3.19253902e+01 -2.38653374e+01 -2.12510452e+01\n",
      " -9.19464207e+00 -1.29695063e+01 -1.92252884e+01 -3.70474815e+00\n",
      " -2.09867096e+01  9.58110571e-01 -2.16735516e+01 -5.31903410e+00\n",
      " -1.10358829e+01 -1.03974533e+01 -1.19409599e+01 -8.03185558e+00\n",
      " -1.37130070e+01 -7.08648062e+00 -8.36725616e+00  2.27544951e+00\n",
      "  9.75155413e-01  1.17445765e+01  5.38146257e+00  9.60692787e+00\n",
      "  6.95992517e+00  9.21212101e+00  1.02973766e+01  1.20698681e+01\n",
      "  9.84880543e+00  8.19135666e+00  2.30051231e+00  3.31454563e+00\n",
      "  4.71673822e+00  4.91703415e+00  2.95189667e+00 -3.65189090e-02\n",
      "  4.31435645e-01  4.05591279e-01  3.96214724e-01  3.96962672e-01\n",
      "  4.28109407e-01  4.97069478e-01  5.28852880e-01  6.03578627e-01\n",
      "  6.23844266e-01  5.69440782e-01  5.70043802e-01  4.93273020e-01\n",
      "  5.22305936e-06  6.58757017e-06  1.73842989e-06  3.08892709e-06\n",
      "  1.41703087e-04  4.63715615e-03  3.21895033e-02  8.75838026e-02\n",
      "  3.16878080e-01  4.50642854e-01  1.55520201e-01  7.47727081e-02\n",
      "  5.52864652e-03  5.59781352e-03  1.75877791e-02  7.01451302e-02\n",
      "  2.10047036e-01  3.44876736e-01  3.69307101e-01  8.14439416e-01\n",
      "  9.80033338e-01  6.11360073e-01  3.03492606e-01  1.61170781e-01\n",
      "  1.13530807e-01  1.53493062e-01  1.34799242e-01  7.12139308e-02\n",
      "  1.59810051e-01  4.17515606e-01  2.41700903e-01  2.67462581e-01\n",
      "  2.69759119e-01  4.00373727e-01  2.42776483e-01  2.14622170e-02\n",
      "  2.25165803e-02  3.26183215e-02  9.31354985e-02  1.93803668e-01\n",
      "  1.67093605e-01  1.11958593e-01  1.12469755e-01  1.07132874e-01\n",
      "  5.29374778e-02  2.77095027e-02  7.54246907e-03  5.20841740e-02\n",
      "  7.96832591e-02  3.29852328e-02  1.59372017e-02  7.31231691e-03\n",
      "  3.66141275e-03  7.56321335e-03  4.00668494e-02  3.80828567e-02\n",
      "  1.15761086e-02  3.14180786e-03  3.13345110e-03  5.78514859e-03\n",
      "  7.81782437e-03  4.28408291e-03  6.95276726e-03  7.89244846e-03\n",
      "  2.00302415e-02  1.04600126e-02  5.49266767e-03  6.52928883e-03\n",
      "  7.75509700e-03  3.35493237e-02  6.12288862e-02  8.39518756e-03\n",
      "  1.57000441e-02  1.51633164e-02  5.53201465e-03  4.40909341e-03\n",
      "  7.32575729e-03  9.76703316e-03  6.74804254e-03  1.15969749e-02\n",
      "  6.02912670e-03  1.32855475e-02  1.15346638e-02  1.59770343e-02\n",
      "  6.90765027e-03  3.22426087e-03  3.24725988e-03  2.55440734e-03\n",
      "  8.23543873e-04  9.92467161e-04  1.39581854e-03  1.20097864e-03\n",
      "  9.74594790e-04  1.39149057e-03  1.52688427e-03  1.42716512e-03\n",
      "  1.50512659e-03  1.45289360e-03  2.09446135e-03  1.76572974e-03\n",
      "  1.74572633e-03  1.83597300e-03  9.70088469e-04  1.35469157e-03\n",
      "  1.13963056e-03  5.52473008e-04  4.68714774e-04  4.66191588e-04\n",
      "  5.36505191e-04  7.26732542e-04  6.04463159e-04  8.62616696e-04\n",
      "  1.19063701e-03  1.17372244e-03  1.84840534e-03  2.09697941e-03\n",
      "  2.46227742e-03  3.18145123e-03  5.54146618e-03  4.68837749e-03\n",
      "  4.09404282e-03  4.42630844e-03  3.13776871e-03  1.94298953e-03\n",
      "  1.62055995e-03  1.02096063e-03  4.95623623e-04  2.35946325e-04]\n",
      "\n",
      "[-3.27238281e+02  4.20527344e+01 -2.23328285e+01  7.62453413e+00\n",
      " -2.80519333e+01 -3.38638420e+01 -2.89812717e+01 -1.92962189e+01\n",
      " -4.62100315e+00 -2.35306854e+01 -1.42800999e+01 -8.37645245e+00\n",
      " -1.59653254e+01 -5.91663980e+00 -1.48133926e+01 -1.08316002e+01\n",
      " -1.73107624e+01 -1.21863432e+01 -5.84546947e+00 -1.34915674e+00\n",
      "  6.82881498e+00  7.67795849e+00  1.41194308e+00  8.12555981e+00\n",
      "  4.08835268e+00  9.95974350e+00  6.51758623e+00  4.66674852e+00\n",
      " -1.74756312e+00 -3.31271720e+00 -1.37062395e+00  2.37763810e+00\n",
      "  5.26875925e+00  8.46008420e-01 -4.24242306e+00  1.69172096e+00\n",
      "  5.54016876e+00  1.39967167e+00 -2.89575624e+00 -5.22586679e+00\n",
      "  4.93030995e-01  4.66629148e-01  4.19589192e-01  3.90589654e-01\n",
      "  4.03277218e-01  4.67789203e-01  4.71158594e-01  4.36400533e-01\n",
      "  4.89012480e-01  5.44477344e-01  6.42322898e-01  6.48333013e-01\n",
      "  1.99440947e-05  1.13367323e-05  3.95063435e-05  7.50641993e-05\n",
      "  9.73065617e-05  9.64853854e-04  4.69697081e-02  8.64609033e-02\n",
      "  2.52270341e-01  8.18948388e-01  1.51936221e+00  1.41013288e+00\n",
      "  4.93545413e-01  1.02136648e+00  1.54813135e+00  2.13876858e-01\n",
      "  1.38682619e-01  1.55451402e-01  3.68768930e-01  1.76526618e+00\n",
      "  3.55447555e+00  1.81496358e+00  4.16925400e-01  9.83051300e-01\n",
      "  8.63440692e-01  8.46171558e-01  6.87824368e-01  2.48175725e-01\n",
      "  4.04925853e-01  3.50019246e-01  4.46982473e-01  1.08882093e+00\n",
      "  6.89071178e-01  1.08507864e-01  4.35911343e-02  8.25668693e-01\n",
      "  1.91134763e+00  4.79797661e-01  6.15451455e-01  8.50954533e-01\n",
      "  8.32895339e-01  2.29482621e-01  5.69014587e-02  1.61284544e-02\n",
      "  2.96735275e-03  1.28719548e-03  1.61165223e-02  9.04489011e-02\n",
      "  1.22335374e-01  1.35644600e-01  6.49674758e-02  6.52692616e-02\n",
      "  1.01890318e-01  3.19519565e-02  2.44728457e-02  6.54780269e-02\n",
      "  2.80195832e-01  7.96436816e-02  4.53470349e-02  4.94894199e-02\n",
      "  3.30767855e-02  5.24654165e-02  7.42692724e-02  1.18049629e-01\n",
      "  5.18384054e-02  3.36051099e-02  2.03280523e-02  2.76661422e-02\n",
      "  2.37346850e-02  3.53368558e-02  7.45903626e-02  5.56712784e-02\n",
      "  1.73982996e-02  1.59997456e-02  1.76088139e-02  1.52144190e-02\n",
      "  2.37474795e-02  1.80935450e-02  3.16748209e-02  2.38337833e-02\n",
      "  1.18331071e-02  1.05729559e-02  1.21261030e-02  5.26797399e-03\n",
      "  9.89039149e-03  2.72507258e-02  1.50512643e-02  8.23340937e-03\n",
      "  9.10233054e-03  1.47558060e-02  1.00414036e-02  8.04108661e-03\n",
      "  2.01477669e-02  1.84298083e-02  2.99606305e-02  1.34353861e-02\n",
      "  2.94859689e-02  1.64937079e-02  1.55971125e-02  3.85024250e-02\n",
      "  3.28433067e-02  1.78599693e-02  1.21532790e-02  4.07102657e-03\n",
      "  2.12636404e-03  1.64637587e-03  1.00848777e-03  1.50509691e-03\n",
      "  1.16457883e-03  1.81127107e-03  1.73793128e-03  2.22291402e-03\n",
      "  2.66209408e-03  2.36246898e-03  2.89529259e-03  4.90518613e-03\n",
      "  7.22279307e-03  9.44575015e-03  8.14539567e-03  8.74600559e-03\n",
      "  1.08257718e-02  8.79576150e-03  1.48499114e-02  1.25518758e-02\n",
      "  1.00133410e-02  9.17554181e-03  5.38028590e-03  2.25360948e-03]\n",
      "\n",
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "#Get the shape of the training and testing datasets\n",
    "print((x_train[0]))\n",
    "print()\n",
    "print((x_test[0]))\n",
    "print()\n",
    "#Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.01, \n",
    "                    batch_size=256, \n",
    "                    epsilon=1e-08, \n",
    "                    hidden_layer_sizes=(300,), \n",
    "                    learning_rate='adaptive', \n",
    "                    max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING THE MODEL\n",
    "import pickle\n",
    "# Save the Modle to file in the current working directory\n",
    "#For any new testing data other than the data in dataset\n",
    "\n",
    "Pkl_Filename = \"Emotion_Voice_Detection_Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Emotion_Voice_Detection_Model = pickle.load(file)\n",
    "\n",
    "Emotion_Voice_Detection_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'angry', 'angry', 'calm', 'happy', 'calm', 'angry',\n",
       "       'happy', 'happy', 'happy', 'disgust', 'disgust', 'disgust', 'calm',\n",
       "       'angry', 'calm', 'angry', 'happy', 'angry', 'angry', 'happy',\n",
       "       'angry', 'angry', 'disgust', 'happy', 'angry', 'angry', 'happy',\n",
       "       'disgust', 'calm', 'happy', 'happy', 'angry', 'happy', 'happy',\n",
       "       'calm', 'happy', 'disgust', 'calm', 'angry', 'disgust', 'calm',\n",
       "       'angry', 'disgust', 'calm', 'disgust', 'disgust', 'angry',\n",
       "       'disgust', 'angry', 'calm', 'angry', 'angry', 'angry', 'calm',\n",
       "       'happy', 'calm', 'angry', 'happy', 'calm', 'calm', 'angry',\n",
       "       'disgust', 'angry', 'calm', 'disgust', 'calm', 'happy', 'happy',\n",
       "       'happy', 'calm', 'calm', 'happy', 'happy', 'calm', 'happy',\n",
       "       'happy', 'happy', 'disgust', 'calm', 'calm', 'calm', 'angry',\n",
       "       'disgust', 'disgust', 'happy', 'disgust', 'angry', 'disgust',\n",
       "       'angry', 'disgust', 'disgust', 'calm', 'disgust', 'calm',\n",
       "       'disgust', 'angry', 'disgust', 'disgust', 'calm', 'calm', 'calm',\n",
       "       'disgust', 'happy', 'calm', 'happy', 'calm', 'happy', 'disgust',\n",
       "       'disgust', 'disgust', 'disgust', 'angry', 'happy', 'disgust',\n",
       "       'angry', 'happy', 'calm', 'angry', 'happy', 'angry', 'angry',\n",
       "       'happy', 'disgust', 'calm', 'angry', 'angry', 'happy', 'happy',\n",
       "       'disgust', 'happy', 'disgust', 'angry', 'angry', 'calm', 'calm',\n",
       "       'happy', 'angry', 'angry', 'happy', 'calm', 'calm', 'disgust',\n",
       "       'happy', 'disgust', 'disgust', 'happy', 'angry', 'angry', 'calm',\n",
       "       'disgust', 'calm', 'happy', 'angry', 'calm', 'calm', 'angry',\n",
       "       'angry', 'calm', 'disgust', 'calm', 'disgust', 'happy', 'calm',\n",
       "       'calm', 'calm', 'disgust', 'happy', 'angry', 'angry', 'happy',\n",
       "       'disgust', 'happy', 'calm', 'calm', 'happy', 'disgust', 'happy',\n",
       "       'angry', 'angry', 'angry', 'calm', 'calm', 'happy', 'angry',\n",
       "       'disgust', 'happy', 'disgust', 'disgust', 'happy', 'disgust',\n",
       "       'disgust'], dtype='<U7')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=Emotion_Voice_Detection_Model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[37  3  7  3]\n",
      " [ 0 39  5  0]\n",
      " [ 4  3 32  2]\n",
      " [ 7  3  3 44]]\n",
      "\n",
      "Accuracy Score  0.7916666666666666\n",
      "\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.77      0.74      0.76        50\n",
      "        calm       0.81      0.89      0.85        44\n",
      "     disgust       0.68      0.78      0.73        41\n",
      "       happy       0.90      0.77      0.83        57\n",
      "\n",
      "    accuracy                           0.79       192\n",
      "   macro avg       0.79      0.79      0.79       192\n",
      "weighted avg       0.80      0.79      0.79       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "results=confusion_matrix(y_test,y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(results)\n",
    "print()\n",
    "print('Accuracy Score ',accuracy_score(y_test,y_pred))\n",
    "print()\n",
    "print('Report')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    predictions                file_names\n",
      "0         happy  03-01-03-02-02-01-16.wav\n",
      "1         angry  03-01-03-01-02-01-17.wav\n",
      "2         angry  03-01-03-01-02-02-05.wav\n",
      "3          calm  03-01-02-01-01-01-21.wav\n",
      "4         happy  03-01-05-02-01-01-21.wav\n",
      "..          ...                       ...\n",
      "187     disgust  03-01-02-02-02-01-05.wav\n",
      "188     disgust  03-01-07-01-01-02-20.wav\n",
      "189       happy  03-01-03-01-01-01-13.wav\n",
      "190     disgust  03-01-07-01-02-01-02.wav\n",
      "191     disgust  03-01-03-01-01-02-17.wav\n",
      "\n",
      "[192 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Store the Prediction probabilities into CSV file \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "y_pred1 = pd.DataFrame(y_pred, columns=['predictions'])\n",
    "y_pred1['file_names'] = test_filename\n",
    "print(y_pred1)\n",
    "y_pred1.to_csv('predictionfinal.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
